{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "V6H60ITmjY7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b08f2b76-8ac6-4bd7-a955-1865bdb77def"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 697 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.8 [186 kB]\n",
            "Fetched 186 kB in 0s (1,831 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126281 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.8_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.8) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.8) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract, pdf2image\n",
            "Successfully installed pdf2image-1.17.0 pytesseract-0.3.13\n"
          ]
        }
      ],
      "source": [
        "!apt-get install poppler-utils\n",
        "!pip install pdf2image pytesseract pillow opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "from collections import defaultdict\n",
        "from pdf2image import convert_from_path\n"
      ],
      "metadata": {
        "id": "p7LA5vrNLLki"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pdf2image import convert_from_path\n",
        "\n",
        "def convert_pdf_to_images(pdf_path, output_image_folder):\n",
        "    os.makedirs(output_image_folder, exist_ok=True)\n",
        "\n",
        "    # Get filename without extension for naming\n",
        "    base_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
        "\n",
        "    # Convert all pages to images\n",
        "    images = convert_from_path(pdf_path, dpi=300)\n",
        "\n",
        "    for idx, image in enumerate(images):\n",
        "        image_filename = f\"{base_name}_page_{idx+1}.png\"\n",
        "        output_path = os.path.join(output_image_folder, image_filename)\n",
        "        image.save(output_path, \"PNG\")\n",
        "        print(f\"Saved image: {output_path}\")\n"
      ],
      "metadata": {
        "id": "EKYDkAg8MlQ6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_pdf_to_images(\"/content/pdfs/1900_spotCheck.pdf\", \"/content/pdf_images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZGdH-LRMs8m",
        "outputId": "8d07e12b-8422-4750-f695-9dd8bbfcc763"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved image: /content/pdf_images/1900_spotCheck_page_1.png\n",
            "Saved image: /content/pdf_images/1900_spotCheck_page_2.png\n",
            "Saved image: /content/pdf_images/1900_spotCheck_page_3.png\n",
            "Saved image: /content/pdf_images/1900_spotCheck_page_4.png\n",
            "Saved image: /content/pdf_images/1900_spotCheck_page_5.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if image is None:\n",
        "        print(f\"Failed to load: {image_path}\")\n",
        "        return None\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Contrast\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    enhanced = clahe.apply(image)\n",
        "\n",
        "    # Blur and threshold\n",
        "    blurred = cv2.GaussianBlur(enhanced, (3, 3), 0)\n",
        "    _, otsu = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Morphological clean-up\n",
        "    kernel_open = np.ones((2, 2), np.uint8)\n",
        "    opened = cv2.morphologyEx(otsu, cv2.MORPH_OPEN, kernel_open)\n",
        "    kernel_dilate = np.ones((2, 1), np.uint8)\n",
        "    dilated = cv2.dilate(opened, kernel_dilate, iterations=1)\n",
        "\n",
        "    return dilated\n"
      ],
      "metadata": {
        "id": "BpapoL9ULW4R"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_and_crop_columns(image_path, output_dir, base_filename, min_height_ratio=0.2):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Load image in grayscale\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if image is None:\n",
        "        print(f\"❌ Cannot load: {image_path}\")\n",
        "        return []\n",
        "\n",
        "    height, width = image.shape\n",
        "    min_height = int(min_height_ratio * height)\n",
        "\n",
        "    # Binarize\n",
        "    _, binary = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Vertical line detection\n",
        "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, height // 20))\n",
        "    vertical_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, vertical_kernel, iterations=1)\n",
        "\n",
        "    # Find contours and filter by height\n",
        "    contours, _ = cv2.findContours(vertical_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    column_boxes = [cv2.boundingRect(c) for c in contours]\n",
        "    tall_boxes = [box for box in column_boxes if box[3] >= min_height]\n",
        "    tall_boxes.sort(key=lambda b: b[0])\n",
        "\n",
        "    x_coords = [x for (x, y, w, h) in tall_boxes]\n",
        "    print(f\"Tall vertical line x-positions: {x_coords}\")\n",
        "\n",
        "    if not x_coords:\n",
        "        print(\" No tall vertical lines found.\")\n",
        "        return []\n",
        "\n",
        "    # Find the line closest to center\n",
        "    center_x = width // 2\n",
        "    x_cut = min(x_coords, key=lambda x: abs(x - center_x))\n",
        "    print(f\"✅ Splitting at x={x_cut}, nearest to center x={center_x}\")\n",
        "\n",
        "    cropped_paths = []\n",
        "\n",
        "    # Left column\n",
        "    left_crop = image[:, 0:x_cut]\n",
        "    left_path = os.path.join(output_dir, f\"{base_filename}_left.png\")\n",
        "    cv2.imwrite(left_path, left_crop)\n",
        "    cropped_paths.append(left_path)\n",
        "\n",
        "    # Right column\n",
        "    right_crop = image[:, x_cut:width]\n",
        "    right_path = os.path.join(output_dir, f\"{base_filename}_right.png\")\n",
        "    cv2.imwrite(right_path, right_crop)\n",
        "    cropped_paths.append(right_path)\n",
        "\n",
        "    return cropped_paths\n"
      ],
      "metadata": {
        "id": "L9G1QNxULaxr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ocr_columns(cropped_paths):\n",
        "    full_text = \"\"\n",
        "    for idx, img_path in enumerate(sorted(cropped_paths)):\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "        column_text = pytesseract.image_to_string(binary, config=\"--psm 4\")\n",
        "        full_text += f\"\\n### Column {idx + 1} ({os.path.basename(img_path)}) ###\\n{column_text.strip()}\\n\"\n",
        "    return full_text\n"
      ],
      "metadata": {
        "id": "sDJMvrvmLfYS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "def process_all_years(input_folder=\"/content/pdf_images\",\n",
        "                      output_text_folder=\"/content/ocr_texts\",\n",
        "                      column_crop_root=\"/content/column_crops\"):\n",
        "\n",
        "    os.makedirs(output_text_folder, exist_ok=True)\n",
        "    os.makedirs(column_crop_root, exist_ok=True)\n",
        "\n",
        "    year_to_images = defaultdict(list)\n",
        "\n",
        "    # Step 1: Group images by year\n",
        "    for image_file in sorted(os.listdir(input_folder)):\n",
        "        if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            year = image_file.split(\"_\")[0]\n",
        "            year_to_images[year].append(os.path.join(input_folder, image_file))\n",
        "            print(f\"Found image: {image_file} (Year: {year})\")\n",
        "\n",
        "    print(f\"\\nDetected years: {list(year_to_images.keys())}\\n\")\n",
        "\n",
        "    # Step 2: Process each year\n",
        "    for year, image_paths in year_to_images.items():\n",
        "        print(f\"Processing year: {year} ({len(image_paths)} pages)\")\n",
        "\n",
        "        for img_path in sorted(image_paths):\n",
        "            img_name = os.path.basename(img_path)\n",
        "            parts = img_name.split(\"_\")\n",
        "            if len(parts) >= 3:\n",
        "                page_id = parts[3].split(\".\")[0]  # e.g., 1 from 1900_batch_1.png\n",
        "            else:\n",
        "                page_id = \"unknown\"\n",
        "\n",
        "            print(f\"  Processing page: {img_name}\")\n",
        "\n",
        "            # Step 2a: Preprocess image\n",
        "            preprocessed = preprocess_image(img_path)\n",
        "            if preprocessed is None:\n",
        "                print(f\"  Skipping {img_name} (preprocessing failed)\")\n",
        "                continue\n",
        "\n",
        "            # Step 2b: Detect and crop columns, save to page-specific folder\n",
        "            column_output_dir = os.path.join(column_crop_root, f\"{year}_page_{page_id}\")\n",
        "            os.makedirs(column_output_dir, exist_ok=True)\n",
        "\n",
        "            cropped_columns = detect_and_crop_columns(\n",
        "                img_path,\n",
        "                output_dir=column_output_dir,\n",
        "                base_filename=f\"{year}_page_{page_id}\"\n",
        "            )\n",
        "\n",
        "            if not cropped_columns:\n",
        "                print(f\"  No columns detected on {img_name}. Skipping OCR.\")\n",
        "                continue\n",
        "\n",
        "            # Step 2c: OCR on cropped columns\n",
        "            page_text = ocr_columns(cropped_columns)\n",
        "\n",
        "            # Step 2d: Save OCR text for this page\n",
        "            output_text_path = os.path.join(output_text_folder, f\"{year}_page_{page_id}.txt\")\n",
        "            with open(output_text_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(page_text)\n",
        "\n",
        "            print(f\"  Saved OCR text to {output_text_path}\")\n",
        "\n",
        "        print(f\"Completed processing for year: {year}\\n\")\n"
      ],
      "metadata": {
        "id": "SE4TiCX0Lgk0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_all_years()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoM9PjRfMIZU",
        "outputId": "9c353840-d25a-47a8-c415-d06a026c52e1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found image: 1900_spotCheck_page_1.png (Year: 1900)\n",
            "Found image: 1900_spotCheck_page_2.png (Year: 1900)\n",
            "Found image: 1900_spotCheck_page_3.png (Year: 1900)\n",
            "Found image: 1900_spotCheck_page_4.png (Year: 1900)\n",
            "Found image: 1900_spotCheck_page_5.png (Year: 1900)\n",
            "\n",
            "Detected years: ['1900']\n",
            "\n",
            "Processing year: 1900 (5 pages)\n",
            "  Processing page: 1900_spotCheck_page_1.png\n",
            "Tall vertical line x-positions: [122, 126, 179, 185, 441, 1414, 2381]\n",
            "✅ Splitting at x=1414, nearest to center x=1200\n",
            "  Saved OCR text to /content/ocr_texts/1900_page_1.txt\n",
            "  Processing page: 1900_spotCheck_page_2.png\n",
            "Tall vertical line x-positions: [989, 1961]\n",
            "✅ Splitting at x=989, nearest to center x=1200\n",
            "  Saved OCR text to /content/ocr_texts/1900_page_2.txt\n",
            "  Processing page: 1900_spotCheck_page_3.png\n",
            "Tall vertical line x-positions: [60, 163, 363, 363, 1397]\n",
            "✅ Splitting at x=1397, nearest to center x=1200\n",
            "  Saved OCR text to /content/ocr_texts/1900_page_3.txt\n",
            "  Processing page: 1900_spotCheck_page_4.png\n",
            "Tall vertical line x-positions: [976, 1959]\n",
            "✅ Splitting at x=976, nearest to center x=1200\n",
            "  Saved OCR text to /content/ocr_texts/1900_page_4.txt\n",
            "  Processing page: 1900_spotCheck_page_5.png\n",
            "Tall vertical line x-positions: [99, 152, 417, 1381, 2379]\n",
            "✅ Splitting at x=1381, nearest to center x=1200\n",
            "  Saved OCR text to /content/ocr_texts/1900_page_5.txt\n",
            "Completed processing for year: 1900\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall google-generativeai -y\n",
        "!pip install --no-cache-dir google-generativeai\n"
      ],
      "metadata": {
        "id": "xwdHIGr5wDGK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "outputId": "8a75efa3-2996-471a-9178-8e21a61c602b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: google-generativeai 0.8.5\n",
            "Uninstalling google-generativeai-0.8.5:\n",
            "  Successfully uninstalled google-generativeai-0.8.5\n",
            "Collecting google-generativeai\n",
            "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.175.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.6.15)\n",
            "Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: google-generativeai\n",
            "Successfully installed google-generativeai-0.8.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "19c94ff181bd43199efdd4ccdaebf118"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=\"AIzaSyDoZBP5UizAEzuGs8f6WJHyDV-SAE2bCzI\")\n",
        "\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')"
      ],
      "metadata": {
        "id": "GjCwixHp_cin"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import json\n",
        "import re\n",
        "\n",
        "# ===  Read OCR Text and Chunk ===\n",
        "def read_and_chunk_file(file_path, chunk_size=1500):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "\n",
        "    text = re.sub(r'\\n+', '\\n', text.strip())\n",
        "    lines = text.split('\\n')\n",
        "\n",
        "    chunks = []\n",
        "    current = []\n",
        "    length = 0\n",
        "\n",
        "    for line in lines:\n",
        "        current.append(line)\n",
        "        length += len(line)\n",
        "        if length >= chunk_size:\n",
        "            chunks.append('\\n'.join(current))\n",
        "            current = []\n",
        "            length = 0\n",
        "\n",
        "    if current:\n",
        "        chunks.append('\\n'.join(current))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "c1KWU-bLnVbJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# === Gemini Prompt: Extract ALL Persons from Chunk ===\n",
        "def extract_all_people_from_chunk(chunk, directory_name=\"Minneapolis 1900\", page_number=104):\n",
        "    prompt = f\"\"\"\n",
        "From the following historical directory OCR text, extract ALL person records and return them as a JSON array.\n",
        "Each person object should follow this format:\n",
        "\n",
        "{{\n",
        "  \"FirstName\": \"...\",\n",
        "  \"LastName\": \"...\",\n",
        "  \"Spouse\": \"...\",\n",
        "  \"Occupation\": \"...\",\n",
        "  \"CompanyName\": \"...\",\n",
        "  \"HomeAddress\": {{\n",
        "    \"StreetNumber\": \"...\",\n",
        "    \"StreetName\": \"...\",\n",
        "    \"ApartmentOrUnit\": \"...\",\n",
        "    \"ResidenceIndicator\": \"h\" | \"w\" | null\n",
        "  }},\n",
        "  \"WorkAddress\": null,\n",
        "  \"Telephone\": null,\n",
        "  \"DirectoryName\": \"{directory_name}\",\n",
        "  \"PageNumber\": {page_number}\n",
        "}}\n",
        "\n",
        "If no people are found in the chunk, return an empty list: `[]`.\n",
        "\n",
        "OCR TEXT:\n",
        "\\\"\\\"\\\"\n",
        "{chunk}\n",
        "\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        content = response.text.strip()\n",
        "\n",
        "        if content.startswith(\"```json\"):\n",
        "            content = content.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "\n",
        "        data = json.loads(content)\n",
        "        if isinstance(data, list):\n",
        "            return data\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(\" Could not parse Gemini output:\", e)\n",
        "        print(\"Response was:\\n\", response.text)\n",
        "        return []\n"
      ],
      "metadata": {
        "id": "ORnenuiJpvXm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===  Loop Over Chunks and Collect ALL People ===\n",
        "def extract_all_people(file_path):\n",
        "    chunks = read_and_chunk_file(file_path)\n",
        "    all_people = []\n",
        "\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        print(f\"🔍 Processing chunk {i+1}/{len(chunks)}...\")\n",
        "        people = extract_all_people_from_chunk(chunk)\n",
        "        all_people.extend(people)\n",
        "\n",
        "    return all_people"
      ],
      "metadata": {
        "id": "MSho2XQVwUqf"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===  Save Results ===\n",
        "def save_to_json(data, output_file='extracted_people.json'):\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
        "    print(f\"\\n Extracted {len(data)} people. Saved to '{output_file}'.\")\n"
      ],
      "metadata": {
        "id": "HZHWrXyGwbMV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === MAIN ===\n",
        "import os\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    all_people = []\n",
        "\n",
        "    ocr_folder = \"/content/ocr_texts\"\n",
        "    for txt_file in sorted(os.listdir(ocr_folder)):\n",
        "        if txt_file.endswith(\".txt\"):\n",
        "            txt_path = os.path.join(ocr_folder, txt_file)\n",
        "            print(f\"Processing OCR file: {txt_file}\")\n",
        "            people = extract_all_people(txt_path)\n",
        "            all_people.extend(people)\n",
        "\n",
        "    save_to_json(all_people)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "EyxYLUq_wpbW",
        "outputId": "426b959d-9e79-4bc9-aba8-5a58bb13ef35"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing OCR file: 1900_page_1.txt\n",
            "🔍 Processing chunk 1/3...\n",
            "🔍 Processing chunk 2/3...\n",
            "🔍 Processing chunk 3/3...\n",
            "Processing OCR file: 1900_page_2.txt\n",
            "🔍 Processing chunk 1/4...\n",
            "🔍 Processing chunk 2/4...\n",
            "🔍 Processing chunk 3/4...\n",
            "🔍 Processing chunk 4/4...\n",
            "Processing OCR file: 1900_page_3.txt\n",
            "🔍 Processing chunk 1/3...\n",
            "🔍 Processing chunk 2/3...\n",
            "🔍 Processing chunk 3/3...\n",
            "Processing OCR file: 1900_page_4.txt\n",
            "🔍 Processing chunk 1/4...\n",
            "🔍 Processing chunk 2/4...\n",
            "🔍 Processing chunk 3/4...\n",
            "🔍 Processing chunk 4/4...\n",
            "Processing OCR file: 1900_page_5.txt\n",
            "🔍 Processing chunk 1/3...\n",
            "🔍 Processing chunk 2/3...\n",
            "🔍 Processing chunk 3/3...\n",
            "\n",
            " Extracted 388 people. Saved to 'extracted_people.json'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7WKrDrTB5_SL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}